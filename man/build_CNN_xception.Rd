% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deepCNN.r
\name{build_CNN_xception}
\alias{build_CNN_xception}
\title{Build Xception}
\usage{
build_CNN_xception(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  classes = 1000,
  classifier_activation = "softmax"
)
}
\arguments{
\item{include_top}{Whether to include the fully-connected layer at the top of the network. A model without a top will output activations from the last convolutional or pooling layer directly.}

\item{weights}{One of \code{NULL} (random initialization), \code{'imagenet'} (pre-trained weights), an \code{array}, or the path to the weights file to be loaded.}

\item{input_tensor}{Optional tensor to use as image input for the model.}

\item{input_shape}{Dimensionality of the input not including the samples axis.}

\item{classes}{Optional number of classes or labels to classify images into, only to be specified if \code{include_top = TRUE}.}

\item{classifier_activation}{A string or callable for the activation function to use on top layer, only if \code{include_top = TRUE}.}
}
\value{
A CNN model object from type Xception.
}
\description{

}
\details{
The \code{input shape} is usually \code{c(height, width, channels)} for a 2D image. If no input shape is specified the default shape 299x299x3 is used. \cr
  The number of \code{classes} can be computed in three steps. First, build a factor of the labels (classes). Second, use \code{\link{as_CNN_image_Y}} to
  one-hot encode the outcome created in the first step. Third, use \code{\link{nunits}} to get the number of classes. The result is equal to \code{\link{nlevels}} used on the result of the first step.

  For a n-ary classification problem with single-label associations, the output is either one-hot encoded with categorical_crossentropy loss function or binary encoded (0,1) with sparse_categorical_crossentropy loss function. In both cases, the output activation function is softmax. \cr
  For a n-ary classification problem with multi-label associations, the output is one-hot encoded with sigmoid activation function and binary_crossentropy loss function.

  For a regression problem, \code{include_top} must be set to \code{FALSE}. The result can be stored in e.g. \code{base_model} with no trainable weights (\code{base_model$trainable = FALSE}).
  Now new layers can be created and separately stored, e.g. \code{flatten_layer, dense_layer_1, dense_layer_2, output_layer}. Finally the base model and the new layers can be concatenated with \code{model <- keras_model_sequential(layers = c(base_model, flatten_layer, dense_layer_1, dense_layer_2, output_layer))}.
}
\references{
Chollet, F. (2017): Xception: Deep Learning with Depthwise Separable Convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, 2017, pp. 1251-1258. https//doi.org/10.1109/CVPR.2017.195. \cr
  \url{https://arxiv.org/pdf/1610.02357.pdf} \cr

  see also \url{https://github.com/keras-team/keras-applications/blob/master/keras_applications/xception.py}
}
\seealso{
Other Convolutional Neural Network (CNN): 
\code{\link{as_CNN_image_X}()},
\code{\link{as_CNN_image_Y}()},
\code{\link{as_CNN_temp_X}()},
\code{\link{as_CNN_temp_Y}()},
\code{\link{as_images_array}()},
\code{\link{as_images_tensor}()},
\code{\link{build_CNN_alexnet}()},
\code{\link{build_CNN_inception_resnet_v2}()},
\code{\link{build_CNN_inception_v3}()},
\code{\link{build_CNN_lenet5}()},
\code{\link{build_CNN_mobilenet_v2}()},
\code{\link{build_CNN_mobilenet_v3}()},
\code{\link{build_CNN_mobilenet}()},
\code{\link{build_CNN_nasnet}()},
\code{\link{build_CNN_resnet50}()},
\code{\link{build_CNN_vgg16}()},
\code{\link{build_CNN_vgg19}()},
\code{\link{build_CNN_zfnet}()},
\code{\link{images_load}()},
\code{\link{images_resize}()}
}
\concept{Convolutional Neural Network (CNN)}
