% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deepCNN.r
\name{build_CNN_inception_v3}
\alias{build_CNN_inception_v3}
\title{Build Inception v3}
\usage{
build_CNN_inception_v3(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  classes = 1000,
  classifier_activation = "softmax"
)
}
\arguments{
\item{include_top}{Whether to include the fully-connected layer at the top of the network. A model without a top will output activations from the last convolutional or pooling layer directly.}

\item{weights}{One of \code{NULL} (random initialization), \code{'imagenet'} (pre-trained weights), an \code{array}, or the path to the weights file to be loaded.}

\item{input_tensor}{Optional tensor to use as image input for the model.}

\item{input_shape}{Dimensionality of the input not including the samples axis.}

\item{classes}{Optional number of classes or labels to classify images into, only to be specified if \code{include_top = TRUE}.}

\item{classifier_activation}{A string or callable for the activation function to use on top layer, only if \code{include_top = TRUE}.}
}
\value{
A CNN model object from type Inception v3.
}
\description{

}
\details{
The \code{input shape} is usually \code{c(height, width, channels)} for a 2D image. If no input shape is specified the default shape 299x299x3 is used. \cr
  The number of \code{classes} can be computed in three steps. First, build a factor of the labels (classes). Second, use \code{\link{as_CNN_image_Y}} to
  one-hot encode the outcome created in the first step. Third, use \code{\link{nunits}} to get the number of classes. The result is equal to \code{\link{nlevels}} used on the result of the first step.

  For a n-ary classification problem with single-label associations, the output is either one-hot encoded with categorical_crossentropy loss function or binary encoded (0,1) with sparse_categorical_crossentropy loss function. In both cases, the output activation function is softmax. \cr
  For a n-ary classification problem with multi-label associations, the output is one-hot encoded with sigmoid activation function and binary_crossentropy loss function.

  For a task with another top layer block, e.g. a regression problem, use the following code template: \cr

  \code{base_model <- build_CNN_inception_v3(include_top = FALSE)} \cr
  \code{base_model$trainable <- FALSE} \cr
  \code{outputs <- base_model$output \%>\%} \cr
  \code{layer_dense(units = 1, activation = "linear")} \cr
  \code{model <- keras_model(inputs = base_model$input, outputs = outputs)}
}
\references{
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z. (2015): Rethinking the Inception Architecture for Computer Vision. arXiv:1512.00567 [cs]. http://arxiv.org/abs/1512.00567. \cr
  \url{https://arxiv.org/pdf/1512.00567.pdf} \cr

  see also \url{https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py}
}
\seealso{
Other Convolutional Neural Network (CNN): 
\code{\link{as_CNN_image_X}()},
\code{\link{as_CNN_image_Y}()},
\code{\link{as_CNN_temp_X}()},
\code{\link{as_CNN_temp_Y}()},
\code{\link{as_images_array}()},
\code{\link{as_images_tensor}()},
\code{\link{build_CNN_alexnet}()},
\code{\link{build_CNN_inception_resnet_v2}()},
\code{\link{build_CNN_lenet5}()},
\code{\link{build_CNN_mobilenet_v2}()},
\code{\link{build_CNN_mobilenet_v3}()},
\code{\link{build_CNN_mobilenet}()},
\code{\link{build_CNN_nasnet}()},
\code{\link{build_CNN_resnet50}()},
\code{\link{build_CNN_unet}()},
\code{\link{build_CNN_vgg16}()},
\code{\link{build_CNN_vgg19}()},
\code{\link{build_CNN_xception}()},
\code{\link{build_CNN_zfnet}()},
\code{\link{images_load}()},
\code{\link{images_resize}()}
}
\concept{Convolutional Neural Network (CNN)}
