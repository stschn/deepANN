% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deepQuality.r
\name{quantile_loss}
\alias{quantile_loss}
\title{Quantile loss}
\usage{
quantile_loss(y, yhat, q = 0.5)
}
\arguments{
\item{y}{A numeric vector with actual values (to-be values).}

\item{yhat}{A numeric vector with estimated values (as-is values).}

\item{q}{A quantile fraction between 0 and 1.}
}
\value{
Quantile loss.
}
\description{
Quantile loss
}
\details{
This loss function tries to give different penalties to overestimation and underestimation.
  For \code{q = 0.5}, overestimation and underestimation are penalized by the same factor and the median is obtained.
  The smaller the value of \code{q}, the more overestimation is penalized compared to underestimation. A model based on
  it will then try to avoid overestimation approximately \code{(1 - p) / p} times as hard as underestimation.
}
\references{
\url{https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0}
  \url{https://www.evergreeninnovations.co/blog-quantile-loss-function-for-machine-learning/}
}
\seealso{
Other Quality: 
\code{\link{accuracy}()},
\code{\link{huber_loss}()},
\code{\link{log_cosh_loss}()},
\code{\link{mae}()},
\code{\link{mape}()},
\code{\link{mse}()},
\code{\link{rmse}()},
\code{\link{vc}()}
}
\concept{Quality}
