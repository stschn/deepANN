% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/deepCNN.r
\name{build_CNN_mobilenet}
\alias{build_CNN_mobilenet}
\title{Build MobileNet}
\usage{
build_CNN_mobilenet(
  include_top = TRUE,
  weights = "imagenet",
  input_tensor = NULL,
  input_shape = NULL,
  classes = 1000,
  classifier_activation = "softmax",
  alpha = 1,
  depth_multiplier = 1,
  dropout = 0.001
)
}
\arguments{
\item{include_top}{Whether to include the fully-connected layer at the top of the network. A model without a top will output activations from the last convolutional or pooling layer directly.}

\item{weights}{One of \code{NULL} (random initialization), \code{'imagenet'} (pre-trained weights), an \code{array}, or the path to the weights file to be loaded.}

\item{input_tensor}{Optional tensor to use as image input for the model.}

\item{input_shape}{Dimensionality of the input not including the samples axis.}

\item{classes}{Optional number of classes or labels to classify images into, only to be specified if \code{include_top = TRUE}.}

\item{classifier_activation}{A string or callable for the activation function to use on top layer, only if \code{include_top = TRUE}.}

\item{alpha}{Controls the width of the network.
\itemize{
\item if \code{alpha < 1.0}, proportionally decreases the number of filters in each layer.
\item if \code{alpha > 1.0}, proportionally increases the number of filters in each layer.
\item if \code{alpha = 1.0}, default number of filters from the paper are used in each layer.
}}

\item{depth_multiplier}{Depth multiplier for depthwise convolution (also called the resolution multiplier).}

\item{dropout}{Dropout rate.}
}
\value{
A CNN model object from type MobileNet.
}
\description{

}
\details{
The \code{input shape} is usually \code{c(height, width, channels)} for a 2D image. If no input shape is specified the default shape 224x224x3 is used. \cr
The number of \code{classes} can be computed in three steps. First, build a factor of the labels (classes). Second, use \code{\link{as_CNN_image_Y}} to
one-hot encode the outcome created in the first step. Third, use \code{\link{nunits}} to get the number of classes. The result is equal to \code{\link{nlevels}} used on the result of the first step.

For a n-ary classification problem with single-label associations, the output is either one-hot encoded with categorical_crossentropy loss function or binary encoded (0,1) with sparse_categorical_crossentropy loss function. In both cases, the output activation function is softmax. \cr
For a n-ary classification problem with multi-label associations, the output is one-hot encoded with sigmoid activation function and binary_crossentropy loss function.

For a task with another top layer block, e.g. a regression problem, use the following code template: \cr

\code{base_model <- build_CNN_mobilenet(include_top = FALSE)} \cr
\code{base_model$trainable <- FALSE} \cr
\code{outputs <- base_model$output \%>\%} \cr
\code{layer_dense(units = 1, activation = "linear")} \cr
\code{model <- keras_model(inputs = base_model$input, outputs = outputs)}

For a task with another input layer, use the following code template: \cr

\code{inputs <- layer_input(shape = c(256, 256, 3))} \cr
\code{blocks <- inputs \%>\% } \cr
\code{layer_conv_2d_transpose(filters = 3, kernel_size = c(1, 1)) \%>\%} \cr
\code{layer_max_pooling_2d()} \cr
\code{model <- build_CNN_mobilenet(input_tensor = blocks)}
}
\references{
Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H. (2017): MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications. arXiv:1704.04861v1 \link{cs}. https://arxiv.org/abs/1704.04861. \cr
\url{https://arxiv.org/pdf/1704.04861v1.pdf} \cr

see also \url{https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet.py}
}
\seealso{
Other Convolutional Neural Network (CNN): 
\code{\link{as_CNN_image_X}()},
\code{\link{as_CNN_image_Y}()},
\code{\link{as_CNN_temp_X}()},
\code{\link{as_CNN_temp_Y}()},
\code{\link{as_images_array}()},
\code{\link{as_images_tensor}()},
\code{\link{build_CNN_alexnet}()},
\code{\link{build_CNN_inception_resnet_v2}()},
\code{\link{build_CNN_inception_v3}()},
\code{\link{build_CNN_lenet5}()},
\code{\link{build_CNN_mobilenet_v2}()},
\code{\link{build_CNN_mobilenet_v3}()},
\code{\link{build_CNN_nasnet}()},
\code{\link{build_CNN_resnet50}()},
\code{\link{build_CNN_unet}()},
\code{\link{build_CNN_vgg16}()},
\code{\link{build_CNN_vgg19}()},
\code{\link{build_CNN_xception}()},
\code{\link{build_CNN_zfnet}()},
\code{\link{images_load}()},
\code{\link{images_resize}()}
}
\concept{Convolutional Neural Network (CNN)}
